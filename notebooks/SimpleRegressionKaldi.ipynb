{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple linear regression using Kaldi nnet3 set of libraries\n",
    "\n",
    "This notebook is a tutorial which tries to explain the mechanism of designing ANNs using the nnet3 library included in the Kaldi project.\n",
    "\n",
    "Kaldi is a very elaborate speech recognition toolkit with a long history and plenty of tools and models apart from ANNs. \n",
    "\n",
    "*nnet3* is a part of the project that deals with the latest implementation of various DNN architectures. The main difference being the easy configurability of the C++-based library, without having to do any actual C++ programming.\n",
    "\n",
    "As with most Kaldi setups, the usage is based around many small binaries that perform simple, atomic operations. These can be run using shell scripts or from other programming languages with the help of \"exec\" or \"popen\" syscalls.\n",
    "\n",
    "As a convinience, a python library is included with the project that has a few methods to make life easier. As of writing this, everything there is still very much work in progress, so there is no guarantees this notebook will work out-of-the-box in a few months time...\n",
    "\n",
    "Formal documentation to the toolkit and it's ANN portion can be found here: http://kaldi-asr.org/doc/dnn3.html\n",
    "\n",
    "## The setup\n",
    "\n",
    "If you don't have it, you need to download Kaldi. Detailed explanation can be found on http://kaldi-ast.org, but the TL;DR is as follow:\n",
    "\n",
    "  1. cd into some conveninet location and do ```git clone https://github.com/kaldi-asr/kaldi```\n",
    "  2. go to ```kaldi/tools``` and simply do ```make``` in there - if the script mentions you need to install anything, simply install the missing tools/libraries\n",
    "  3. go to ```kaldi/src``` and do ```./configure``` in there - it would be good to have CUDA installed and recognized in this step, as you can benefit from GPU acceleration a lot\n",
    "  4. after configuring simply do ```make``` and wait - if you have a very new version of gcc (>6) it may be a good idea to install something like 4.9 and simply modify the kaldi.mk file \n",
    "  \n",
    "One thing about Kaldi is that it is completely contained in a single directory, which makes it easy to move and locate. That is why most scripts utilized with Kaldi rely on the following path. You need to set this to wherever you stored Kaldi on your computer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KALDI_ROOT='~/apps/kaldi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, we create a small work directory as a subdirectory of this notebook and add to it some files from the Kaldi project:\n",
    "  * a symlink to the steps dir from the WSJ example - this contains lots of useful scripts and the nnet3 python library\n",
    "  * a copy of the path.sh file - used to load the path environment with the locations of all the binaries in the Kaldi project\n",
    "  \n",
    "The path.sh file is also modified to include the actual path to Kaldi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "import fileinput\n",
    "import stat\n",
    "\n",
    "KALDI_ROOT=os.path.expanduser(KALDI_ROOT)\n",
    "KALDI_ROOT=os.path.abspath(KALDI_ROOT)\n",
    "\n",
    "if not os.getcwd().endswith('/work'):\n",
    "    if not os.path.exists('work'):\n",
    "        os.mkdir('work')\n",
    "    os.chdir('work')\n",
    "\n",
    "if not os.path.exists('steps'):\n",
    "    os.symlink(KALDI_ROOT+'/egs/wsj/s5/steps','steps')\n",
    "\n",
    "if not os.path.exists('path.sh'):\n",
    "    copyfile(KALDI_ROOT+'/egs/wsj/s5/path.sh','path.sh')\n",
    "    for line in fileinput.input('path.sh',inplace=True):\n",
    "        if line.startswith('export KALDI_ROOT='):\n",
    "            print 'export KALDI_ROOT='+KALDI_ROOT\n",
    "        else:\n",
    "            print line[:-1]\n",
    "    os.chmod('path.sh',0755)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python library is located in the steps/nnet3 subfolder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('steps/nnet3')\n",
    "\n",
    "import nnet3_train_lib as ntl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we load the library, we have access to all sorts of methods, but RunKaldiCommand should be sufficient for now.\n",
    "\n",
    "The next problem is that while path.sh script is useful if you run programs locally from your terminal, it doesn't work in the Notebook environemt, since the notebook process is already running and we can't modify its environment by running the script in any way. This simple hack prints out the whole path string after running the script and simply modifies the environemnt manually. Make sure you don't run this cell more than once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting PATH=/home/guest/apps/kaldi/src/bin:/home/guest/apps/kaldi/src/chainbin:/home/guest/apps/kaldi/src/featbin:/home/guest/apps/kaldi/src/fgmmbin:/home/guest/apps/kaldi/src/fstbin:/home/guest/apps/kaldi/src/gmmbin:/home/guest/apps/kaldi/src/ivectorbin:/home/guest/apps/kaldi/src/kwsbin:/home/guest/apps/kaldi/src/latbin:/home/guest/apps/kaldi/src/lmbin:/home/guest/apps/kaldi/src/nnet2bin:/home/guest/apps/kaldi/src/nnet3bin:/home/guest/apps/kaldi/src/nnetbin:/home/guest/apps/kaldi/src/online2bin:/home/guest/apps/kaldi/src/onlinebin:/home/guest/apps/kaldi/src/sgmm2bin:/home/guest/apps/kaldi/src/sgmmbin:/home/guest/Desktop/kaldi-nnet/work/utils/:/home/guest/apps/kaldi/tools/openfst/bin:/home/guest/Desktop/kaldi-nnet/work:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/guest/apps/kaldi/tools/srilm/bin:/home/guest/apps/kaldi/tools/srilm/bin/i686-m64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = ntl.RunKaldiCommand('source ./path.sh ; printenv | grep ^PATH=')[0]\n",
    "\n",
    "print 'Setting '+path\n",
    "\n",
    "os.environ['PATH']=path.split('=')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "Linear regression is probably the simplest problem you can implment using an ANN library. The problem is stated like this. Say we define a function using a linear equation, for example:\n",
    "\n",
    "\\begin{equation}\n",
    "y = 0.3 x_1 + 0.1 x_2 + 0.2\n",
    "\\end{equation}\n",
    "\n",
    "Now let's ask our friend to guess the formula of the function, but all we can tell him is what the output is given any input. To him, it's essentially a black-box.\n",
    "\n",
    "To make his life easier, we tell him that the function is linear and that it takes two inputs and gives one output. He may decide to describe his problem thusly:\n",
    "\n",
    "\\begin{equation}\n",
    "y = w_1 \\cdot x_1 + w_2 \\cdot x_2 + b\n",
    "\\end{equation}\n",
    "\n",
    "For any $x_1$ and $x_2$ given to the formula above, with the $w_1$, $w_2$, and $b$ such that the $y$ computed using that function is as close to the one in the unknown, black-box function.\n",
    "\n",
    "To help him solve the proble, we will provide our buddy with a 100 examples of random input-output pairs. First let's define our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def problem(x):\n",
    "        return x[0]*0.3+x[1]*0.1+0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let generate 100 inputs and outputs. You can modify these two cells to see if the rest of the notebook will adjust accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "input_dim=2\n",
    "data_num=100\n",
    "\n",
    "inputs=np.random.random((data_num,input_dim))\n",
    "outputs=np.array([problem(x) for x in inputs])\n",
    "if outputs.ndim==1:\n",
    "        outputs=outputs.reshape(outputs.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data storage\n",
    "\n",
    "Kaldi accepts the inputs to its programs in specific formats. The nnet3 nets accept a specific EGS input format. The python function below converts two numpy arrays into a file stored using that format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_simple_egs(filename,inputs,outputs):\n",
    "    input_dim=inputs.shape[1]\n",
    "    output_dim=outputs.shape[1]\n",
    "    with open(filename,'w') as f:\n",
    "        for i,l in enumerate(inputs):\n",
    "            \n",
    "            f.write('data-{} '.format(i))\n",
    "            f.write('<Nnet3Eg> ')\n",
    "            f.write('<NumIo> {} '.format(input_dim))\n",
    "\n",
    "            f.write('<NnetIo> input ')\n",
    "            f.write('<I1V> 1 <I1> 0 0 0  ')\n",
    "            f.write('[\\n  ')\n",
    "            for d in l:\n",
    "                f.write('{} '.format(d))\n",
    "            f.write(']\\n')\n",
    "            f.write('</NnetIo> ')\n",
    "\n",
    "            f.write('<NnetIo> output ')\n",
    "            f.write('<I1V> 1 <I1> 0 0 0  ')\n",
    "            f.write('[\\n  ')\n",
    "            for d in outputs[i]:\n",
    "                f.write('{} '.format(d))\n",
    "            f.write(']\\n')\n",
    "            f.write('</NnetIo> ')\n",
    "\n",
    "            f.write('</Nnet3Eg> ')\n",
    "            \n",
    "write_simple_egs('nnet.egs',inputs,outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out a few example lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-0 <Nnet3Eg> <NumIo> 2 <NnetIo> input <I1V> 1 <I1> 0 0 0  [\r\n",
      "  0.191519450379 0.62210877104 ]\r\n",
      "</NnetIo> <NnetIo> output <I1V> 1 <I1> 0 0 0  [\r\n",
      "  0.319666712218 ]\r\n",
      "</NnetIo> </Nnet3Eg> data-1 <Nnet3Eg> <NumIo> 2 <NnetIo> input <I1V> 1 <I1> 0 0 0  [\r\n",
      "  0.437727739007 0.785358583714 ]\r\n",
      "</NnetIo> <NnetIo> output <I1V> 1 <I1> 0 0 0  [\r\n",
      "  0.409854180074 ]\r\n",
      "</NnetIo> </Nnet3Eg> data-2 <Nnet3Eg> <NumIo> 2 <NnetIo> input <I1V> 1 <I1> 0 0 0  [\r\n",
      "  0.779975808119 0.272592605283 ]\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 nnet.egs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may look complicated, but it's not that bad:\n",
    "  * each input sequence starts with a unique name followed by an ```<Nnet3Eg>``` xml-linke block - this example creates one value per input sequence, but normally you would create many values per sequence, where one sequence corresponds to one file or utterance\n",
    "  * The ```<Nnet3Eg>``` is followed by a sequence of observation (in this case there is only one per file) which is opened by the ```<NumIo>``` block informing us what is the number of values stored in this observation\n",
    "  * Following that is the sequence of ```<NnetIO>``` blocks with the actual data - in this case we have two such blocks per observation: input and output\n",
    "  * the first item inside the ```<NnetIo>``` block is the name of the data point\n",
    "  * next is the index of the data point - ```<I1V>``` is the number of index values and ```<I1>``` is the actual index values - you can read more about indexes here: http://kaldi-asr.org/doc/dnn3_code_data_types.html#dnn3_dt_datastruct_index\n",
    "  * after that is the actual values of the data - in our case both input and output are expressed in the *dense matrix* form - it's a bit strange  with its use of newlines, but it is a standard form used throughout kaldi\n",
    "  * alternatively, instead of the *dense matrix* form, a *sparse matrix* is sometimes used when trying to express posteriors - it begins with a ```SM``` token followed by ```row=``` and ```dim=``` - it won't be described in this tutorial\n",
    "  \n",
    "  \n",
    "### Config file\n",
    "\n",
    "The whole *nnet3* system is based around the confguration files, which allow creating almost any topology (feed-forward or recurrent) in a graphical manner. This file consists of two sets of information:\n",
    "  * components - describing the sets of weights in the ANN\n",
    "  * nodes - describing the connections between the nodes\n",
    "  \n",
    "In our simple example we create a single component describing the dense weights of the model in an *affine* operation (in other words weighted sum with bias). It has two dimension parameters (input and output) and you can also set the learning rate here. Note that the name of the component is later used in the graph description.\n",
    "\n",
    "Other types of components include different type of fixed (ie constant) and dynamic weight containers and various activation functions. You can also define your own components, if you need to.\n",
    "\n",
    "The second portion of the file include the connections between the individual components. These connections are represented by graph nodes. Two nodes are defined for any model: input-node and output-node. They are linked to input and output values in our EGS file above (note that the names of these nodes match the names of the matrices in the EGS file). \n",
    "\n",
    "The input-node also needs to define the dimension of the input data (for graph construction purposes). Also note that you can have many input nodes per model.\n",
    "\n",
    "All other nodes apart from the input node have an input parameter denoting what they are connected to. Component nodes also have a component attribute linking it to the component from the list above the nodes. The output node can also define an objective function - currently only `quadratic` is available (for MSE) and `linear` (for cross-entropy, but computed on likelihoods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing nnet.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile nnet.config\n",
    "# First the components\n",
    "component name=wts type=AffineComponent input-dim=2 output-dim=1 learning-rate=0.6\n",
    "# Next the nodes\n",
    "input-node name=input dim=2\n",
    "component-node name=wts_node component=wts input=input\n",
    "output-node name=output input=wts_node objective=quadratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network initialization\n",
    "\n",
    "Using the config file, we can create a randomly initialized network using the `nnet3-init` program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnet3-init nnet.config nnet.init \n",
      "LOG (nnet3-init:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to nnet.init\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ntl.RunKaldiCommand('nnet3-init {} {}'.format('nnet.config','nnet.init'))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the description of the network with the `nnet3-info` program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num-parameters: 3\n",
      "modulus: 1\n",
      "input-node name=input dim=2\n",
      "component-node name=wts_node component=wts input=input input-dim=2 output-dim=1\n",
      "output-node name=output input=wts_node dim=1 objective=quadratic\n",
      "component name=wts type=AffineComponent, input-dim=2, output-dim=1, learning-rate=0.6, linear-params-rms=1.089, bias-{mean,stddev}=0.479,0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ntl.RunKaldiCommand('nnet3-info {}'.format('nnet.init'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even draw it to a DOT file (this looks far more impressive for bigger models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnet3-info nnet.init \n",
      "steps/nnet3/dot/nnet3_to_dot.py nnet.dot\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"168pt\" viewBox=\"0.00 0.00 638.17 167.81\" width=\"638pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 163.806)\">\n",
       "<title>nnet3graph</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-163.806 634.17,-163.806 634.17,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- input -->\n",
       "<g class=\"node\" id=\"node1\"><title>input</title>\n",
       "<ellipse cx=\"37.4767\" cy=\"-79.9031\" fill=\"none\" rx=\"37.4533\" ry=\"26.7407\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"37.4767\" y=\"-83.7031\">input</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"37.4767\" y=\"-68.7031\">dim=2</text>\n",
       "</g>\n",
       "<!-- wts_node -->\n",
       "<g class=\"node\" id=\"node2\"><title>wts_node</title>\n",
       "<polygon fill=\"none\" points=\"160.477,-97.9031 92.4767,-97.9031 92.4767,-61.9031 160.477,-61.9031 160.477,-97.9031\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126.477\" y=\"-76.2031\">wts_node</text>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g class=\"node\" id=\"node3\"><title>output</title>\n",
       "<ellipse cx=\"266.477\" cy=\"-79.9031\" fill=\"none\" rx=\"88.2768\" ry=\"26.7407\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.477\" y=\"-83.7031\">output</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.477\" y=\"-68.7031\">objective=quadratic</text>\n",
       "</g>\n",
       "<!-- wtswts_component -->\n",
       "<g class=\"node\" id=\"node4\"><title>wtswts_component</title>\n",
       "<ellipse cx=\"501.477\" cy=\"-79.9031\" fill=\"none\" rx=\"128.887\" ry=\"79.8063\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.477\" y=\"-121.203\">learning-rate = 0.6</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.477\" y=\"-106.203\">bias-{mean,stddev} = 0.479,0</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.477\" y=\"-91.2031\">name = wts</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.477\" y=\"-76.2031\">input-dim = 2</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.477\" y=\"-61.2031\">linear-params-rms = 1.089</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.477\" y=\"-46.2031\">output-dim = 1</text>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501.477\" y=\"-31.2031\">type = AffineComponent</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ntl.RunKaldiCommand('nnet3-info {} | python steps/nnet3/dot/nnet3_to_dot.py {}'.format('nnet.init','nnet.dot'))[1]\n",
    "\n",
    "from IPython.display import SVG\n",
    "from pydot import graph_from_dot_file\n",
    "\n",
    "SVG(graph_from_dot_file('nnet.dot')[0].create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The networks are stored in a binary (comressed) format, but we can see their contents (eg. weights) using the `nnet3-copy` program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Nnet3> \n",
      "input-node name=input dim=2\n",
      "component-node name=wts_node component=wts input=input\n",
      "output-node name=output input=wts_node objective=quadratic\n",
      "\n",
      "<NumComponents> 1 \n",
      "<ComponentName> wts <AffineComponent> <LearningRate> 0.6 <LinearParams>  [\n",
      "  -0.8441005 1.287315 ]\n",
      "<BiasParams>  [ 0.4790476 ]\n",
      "<IsGradient> F </AffineComponent> \n",
      "</Nnet3> \n"
     ]
    }
   ],
   "source": [
    "print ntl.RunKaldiCommand('nnet3-copy --binary=false {} {}'.format('nnet.init','-'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "This network is totally random for now and doesn't do much. This command trains the network using the provided EGS data and stores the trained network into an output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnet3-train nnet.init ark,t:nnet.egs nnet.out \n",
      "WARNING (nnet3-train:SelectGpuId():cu-device.cc:182) Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode\n",
      "LOG (nnet3-train:SelectGpuIdAuto():cu-device.cc:300) Selecting from 1 GPUs\n",
      "LOG (nnet3-train:SelectGpuIdAuto():cu-device.cc:315) cudaSetDevice(0): GeForce GTX 960M\tfree:4014M, used:29M, total:4043M, free/total:0.992829\n",
      "LOG (nnet3-train:SelectGpuIdAuto():cu-device.cc:364) Trying to select device: 0 (automatically), mem_ratio: 0.992829\n",
      "LOG (nnet3-train:SelectGpuIdAuto():cu-device.cc:383) Success selecting device 0 free mem ratio: 0.992829\n",
      "LOG (nnet3-train:FinalizeActiveGpu():cu-device.cc:225) The active GPU is [0]: GeForce GTX 960M\tfree:3996M, used:47M, total:4043M, free/total:0.988378 version 5.0\n",
      "LOG (nnet3-train:PrintTotalStats():nnet-training.cc:187) Overall average objective function for 'output' is -0.0249837 over 100 frames.\n",
      "LOG (nnet3-train:PrintTotalStats():nnet-training.cc:194) [this line is to be parsed by a script:] log-prob-per-frame=-0.0249837\n",
      "LOG (nnet3-train:PrintProfile():cu-device.cc:427) -----\n",
      "[cudevice profile]\n",
      "Destroy\t0.000273228s\n",
      "CuMatrix::Resize\t0.000498772s\n",
      "AddVec\t0.000871897s\n",
      "Set\t0.000876665s\n",
      "CopyRowsFromVec\t0.00103641s\n",
      "AddMatVec\t0.00107932s\n",
      "CuMatrix::SetZero\t0.0010941s\n",
      "CuMatrixBase::CopyFromMat(from CPU)\t0.0013845s\n",
      "CuVector::Resize\t0.00146627s\n",
      "CopyToVec\t0.0017221s\n",
      "CuVector::SetZero\t0.00175309s\n",
      "AddMat\t0.00185108s\n",
      "VecVec\t0.0020411s\n",
      "AddMatMat\t0.00207019s\n",
      "TraceMatMat\t0.00430775s\n",
      "Total GPU time:\t0.0223646s (may involve some double-counting)\n",
      "-----\n",
      "LOG (nnet3-train:PrintMemoryUsage():cu-allocator.cc:127) Memory usage: 44 bytes currently allocated (max: 44); 24 currently in use by user (max: 44); 8/604 calls to Malloc* resulted in CUDA calls.\n",
      "LOG (nnet3-train:PrintMemoryUsage():cu-allocator.cc:134) Time taken in cudaMallocPitch=0, in cudaMalloc=7.12872e-05, in cudaFree=0, in this->MallocPitch()=0.000874043\n",
      "LOG (nnet3-train:PrintMemoryUsage():cu-device.cc:400) Memory used (according to the device): 0 bytes.\n",
      "LOG (nnet3-train:main():nnet3-train.cc:86) Wrote model to nnet.out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ntl.RunKaldiCommand('nnet3-train {} ark,t:{} {}'.format('nnet.init','nnet.egs','nnet.out'))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, to get a better result, it's a good idea to run this several times for a couple of epochs. With such a simple problem and high learning rate, only a few steps is enough to reach equilibrium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Nnet3> \n",
      "input-node name=input dim=2\n",
      "component-node name=wts_node component=wts input=input\n",
      "output-node name=output input=wts_node objective=quadratic\n",
      "\n",
      "<NumComponents> 1 \n",
      "<ComponentName> wts <AffineComponent> <LearningRate> 0.6 <LinearParams>  [\n",
      "  0.2909224 0.1076631 ]\n",
      "<BiasParams>  [ 0.1960226 ]\n",
      "<IsGradient> F </AffineComponent> \n",
      "</Nnet3> \n",
      "<Nnet3> \n",
      "input-node name=input dim=2\n",
      "component-node name=wts_node component=wts input=input\n",
      "output-node name=output input=wts_node objective=quadratic\n",
      "\n",
      "<NumComponents> 1 \n",
      "<ComponentName> wts <AffineComponent> <LearningRate> 0.6 <LinearParams>  [\n",
      "  0.2999439 0.1000724 ]\n",
      "<BiasParams>  [ 0.199928 ]\n",
      "<IsGradient> F </AffineComponent> \n",
      "</Nnet3> \n",
      "<Nnet3> \n",
      "input-node name=input dim=2\n",
      "component-node name=wts_node component=wts input=input\n",
      "output-node name=output input=wts_node objective=quadratic\n",
      "\n",
      "<NumComponents> 1 \n",
      "<ComponentName> wts <AffineComponent> <LearningRate> 0.6 <LinearParams>  [\n",
      "  0.2999998 0.1000008 ]\n",
      "<BiasParams>  [ 0.1999988 ]\n",
      "<IsGradient> F </AffineComponent> \n",
      "</Nnet3> \n",
      "<Nnet3> \n",
      "input-node name=input dim=2\n",
      "component-node name=wts_node component=wts input=input\n",
      "output-node name=output input=wts_node objective=quadratic\n",
      "\n",
      "<NumComponents> 1 \n",
      "<ComponentName> wts <AffineComponent> <LearningRate> 0.6 <LinearParams>  [\n",
      "  0.3 0.1 ]\n",
      "<BiasParams>  [ 0.2 ]\n",
      "<IsGradient> F </AffineComponent> \n",
      "</Nnet3> \n"
     ]
    }
   ],
   "source": [
    "print ntl.RunKaldiCommand('nnet3-copy --binary=false {} {}'.format('nnet.out','-'))[0]\n",
    "for i in range(3):\n",
    "    ntl.RunKaldiCommand('nnet3-train {} ark,t:{} {}'.format('nnet.out','nnet.egs','nnet.out'))\n",
    "    print ntl.RunKaldiCommand('nnet3-copy --binary=false {} {}'.format('nnet.out','-'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you can see that the values of the weights match exactly to the values of our secret equation. The method works!\n",
    "\n",
    "### Computation\n",
    "\n",
    "One final question you may ask is, how can we use a trained network on new data? Well, let's create some random data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97903882  0.88123225]\n",
      " [ 0.62768192  0.93048653]\n",
      " [ 0.72478995  0.71667789]\n",
      " [ 0.04107857  0.43948178]\n",
      " [ 0.28206978  0.33499597]\n",
      " [ 0.08352701  0.76084915]\n",
      " [ 0.50927245  0.66104742]\n",
      " [ 0.63031444  0.37092683]\n",
      " [ 0.44674015  0.41510822]\n",
      " [ 0.48038851  0.98332357]]\n"
     ]
    }
   ],
   "source": [
    "test_num=10\n",
    "\n",
    "test=np.random.random((test_num,input_dim))\n",
    "\n",
    "print test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the values we should get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581834870614\n",
      "0.481353229779\n",
      "0.489104774536\n",
      "0.256271747492\n",
      "0.318120531824\n",
      "0.301143016819\n",
      "0.41888647591\n",
      "0.426187015491\n",
      "0.375532867539\n",
      "0.442448909743\n"
     ]
    }
   ],
   "source": [
    "for x in test:\n",
    "    print problem(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the data in a matrix file, for Kaldi to be able to process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test [\r\n",
      "  0.9790388199339376 0.88123224633892705\r\n",
      "  0.62768192146397517 0.93048653340266563\r\n",
      "  0.72478995310243888 0.71667788605535621\r\n",
      "  0.041078566584183851 0.43948177516747489\r\n",
      "  0.28206978311608777 0.33499596889192729\r\n",
      "  0.083527007044400303 0.76084914705738604\r\n",
      "  0.50927244716395392 0.6610474176084522\r\n",
      "  0.63031444248428148 0.37092682745752747\r\n",
      "  0.44674015173084469 0.41510822019759319\r\n",
      "  0.4803885080134066 0.98332357338846621  ]\r\n"
     ]
    }
   ],
   "source": [
    "with open('test.mat','w') as f:\n",
    "    f.write('test [')\n",
    "    for row in test:\n",
    "        f.write('\\n  ')\n",
    "        f.write(' '.join([`num` for num in row]))\n",
    "    f.write('  ]\\n')\n",
    "%cat test.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the trained net to compute the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  [\n",
      "  0.5818349 \n",
      "  0.4813533 \n",
      "  0.4891048 \n",
      "  0.2562718 \n",
      "  0.3181205 \n",
      "  0.3011431 \n",
      "  0.4188865 \n",
      "  0.426187 \n",
      "  0.3755329 \n",
      "  0.4424489 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ntl.RunKaldiCommand('nnet3-compute {} ark,t:{} ark,t:{}'.format('nnet.out','test.mat','-'))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
